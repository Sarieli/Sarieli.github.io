<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="相关滤波,">










<meta name="description" content="论文地址和补充材料地址渣翻过程中有些语句我也不甚了了，文章以一段原文一段渣翻的形式给出，方便对照。论文中的图请自行去论文查看。论文的实验部分没有翻译。补充材料的翻译放在最后。在个别段落间会插入自己的一些想法。Abstract. Recent years have seen greater interest in the use of discriminative classifiers in tr">
<meta name="keywords" content="相关滤波">
<meta property="og:type" content="article">
<meta property="og:title" content="Exploiting the Circulant Structure of Tracking-by-detection with Kernels 渣翻">
<meta property="og:url" content="http://yoursite.com/2018/11/01/Exploiting the Circulant Structure of Tracking-by-detection with Kernels 渣翻/index.html">
<meta property="og:site_name" content="东门屿">
<meta property="og:description" content="论文地址和补充材料地址渣翻过程中有些语句我也不甚了了，文章以一段原文一段渣翻的形式给出，方便对照。论文中的图请自行去论文查看。论文的实验部分没有翻译。补充材料的翻译放在最后。在个别段落间会插入自己的一些想法。Abstract. Recent years have seen greater interest in the use of discriminative classifiers in tr">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2018-11-21T07:34:09.736Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Exploiting the Circulant Structure of Tracking-by-detection with Kernels 渣翻">
<meta name="twitter:description" content="论文地址和补充材料地址渣翻过程中有些语句我也不甚了了，文章以一段原文一段渣翻的形式给出，方便对照。论文中的图请自行去论文查看。论文的实验部分没有翻译。补充材料的翻译放在最后。在个别段落间会插入自己的一些想法。Abstract. Recent years have seen greater interest in the use of discriminative classifiers in tr">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '473EBY24LB',
      apiKey: 'c5b13ea44f24e9c46ec515b70a0b354a',
      indexName: 'East door island',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/11/01/Exploiting the Circulant Structure of Tracking-by-detection with Kernels 渣翻/">





  <title>Exploiting the Circulant Structure of Tracking-by-detection with Kernels 渣翻 | 东门屿</title>
  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?6e8a99bb1d9d0ffd8cf061e4aa447c03";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">东门屿</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  
  <div class="algolia-popup popup search-popup">
    <div class="algolia-search">
      <div class="algolia-search-input-icon">
        <i class="fa fa-search"></i>
      </div>
      <div class="algolia-search-input" id="algolia-search-input"></div>
    </div>

    <div class="algolia-results">
      <div id="algolia-stats"></div>
      <div id="algolia-hits"></div>
      <div id="algolia-pagination" class="algolia-pagination"></div>
    </div>

    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
  </div>




    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/11/01/Exploiting the Circulant Structure of Tracking-by-detection with Kernels 渣翻/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Sarieli">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="东门屿">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Exploiting the Circulant Structure of Tracking-by-detection with Kernels 渣翻</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-11-01T20:15:45+08:00">
                2018-11-01
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/CV/" itemprop="url" rel="index">
                    <span itemprop="name">CV</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2018/11/01/Exploiting the Circulant Structure of Tracking-by-detection with Kernels 渣翻/" class="leancloud_visitors" data-flag-title="Exploiting the Circulant Structure of Tracking-by-detection with Kernels 渣翻">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  13.6k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  65
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p><a href="http://www.robots.ox.ac.uk/~joao/publications/henriques_eccv2012.pdf" target="_blank" rel="noopener">论文地址</a>和<a href="http://www.robots.ox.ac.uk/~joao/circulant/henriques_eccv2012_supplement2.pdf" target="_blank" rel="noopener">补充材料地址</a><br>渣翻过程中有些语句我也不甚了了，文章以一段原文一段渣翻的形式给出，方便对照。<br>论文中的图请自行去论文查看。<br>论文的实验部分没有翻译。<br>补充材料的翻译放在最后。<br>在个别段落间会插入自己的一些想法。<br><strong>Abstract.</strong> Recent years have seen greater interest in the use of discriminative classifiers in tracking systems, owing to their success in object detection. They are trained online with samples collected during tracking. Unfortunately, the potentially large number of samples becomes a computational burden, which directly conflicts with real-time requirements. On the other hand, limiting the samples may sacrifice performance. Interestingly, we observed that, as we add more and more samples, the problem acquires circulant structure. Using the well-established theory of Circulant matrices, we provide a link to Fourier analysis that opens up the possibility of extremely fast learning and detection with the Fast Fourier Transform. This can be done in the dual space of kernel machines as fast as with linear classifiers. We derive closed-form solutions for training and detection with several types of kernels including the popular Gaussian and polynomial kernels. The resulting tracker achieves performance competitive with the state-of-the-art, can be implemented with only a few lines of code and runs at hundreds of frames-per-second. MATLAB code is provided in the paper (see Algorithm 1).<br><strong>摘要。</strong> 由于其在目标检测的成功应用，近年来，人们对在跟踪系统中使用判别式分类器越发感兴趣。他们对跟踪过程中收集的样本进行在线训练。不幸的是，潜在的大量样本成为了计算负担，这与实时性要求直接冲突。另一方面，限制样本数量可能会牺牲性能。有趣的是，我们观察到，随着我们添加越来越多的样本，该问题就变成了循环结构。利用循环矩阵这一完善的理论，我们提出了其和傅里叶分析的联系，使得通过快速傅里叶变换实现快速学习和检测的成为可能。这可以在核机器的对偶空间中实现得跟线性分类器一样快。我们推导出用于训练和检测的解析解，其使用了几种不同类型的核函数，包括流行的高斯核函数和多项式核函数。由此生成的跟踪器的性能能够与最先进的跟踪器一教高下，其只需少量的代码即可实现并能够以每秒数百帧的速度运行。本文提供MATLAB代码（参见算法1）。</p>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Tracking is a fundamental problem in computer vision, with applications in video surveillance, human-machine interfaces and robot perception. Even though some settings allow for strong assumptions about the target [1, 2], sometimes it is desirable to track an object with little a-priori knowledge. Model-less tracking consists of learning and adapting a representation of the target online. A very successful approach has been tracking-by-detection [3-7]. This stems directly from the development of powerful discriminative methods in machine learning, and their application to detection with offline training. Many of these algorithms can be adapted for online training, where each successful detection provides more information about the target. Almost all of the proposed methods have one thing in common: a sparse sampling strategy [3, 5-7]. In each frame, several samples are collected in the target’s neighborhood, where typically each sample characterizes a subwindow the same size as the target (illustrated in Table 1). Clearly, there is a lot of redundancy, since most of the samples have a large amount of overlap. This underlying structure is usually ignored. Instead, most methods simply collect a small number of samples, because the cost of not doing so would be prohibitive.<br>跟踪是计算机视觉中的一个基本问题，广泛应用于视频监控，人机交互和机器人感知。尽管一些设定考虑到了对目标[1,2]的强烈假设，有时我们希望在几乎没有先验知识的条件下跟踪目标。无模型跟踪包括在线学习和适应目标的表观特征。一种非常成功的方法是检测跟踪[3-7]。这直接源于机器学习中强大的判别方法的发展，以及它们在检测中使用离线训练的应用。很多这些算法可以调整为在线训练形式，这样每次成功检测将提供关于目标的更多信息。几乎所有提出的方法都有一个共同点：稀疏采样策略[3,5-7]。在每一帧中，在目标邻域收集几个样本，一种典型的做法是每个样本用一个与目标大小相同的子窗口来表征（如表1所示）。显然，这会存在很多冗余，因为大多数样本具有大量的重叠。这种底层结构通常被忽略。相反，大多数方法仅收集少量的样本，因为不这样做的代价将是令人望而却步的。<br>The fact that the training data has so much redundancy means that we are probably not exploiting its structure effciently. We propose a new theoretical framework to address this. We show that the process of taking subwindows of an image induces circulant structure. We then establish links to Fourier analysis that allows the use of the Fast Fourier Transform (FFT) to quickly incorporate information from all subwindows, without iterating over them.<br>训练数据存在如此多冗余的事实意味着我们可能没有有效地利用它的结构。我们提出了一个新的理论框架来解决这个问题。我们证明，对一幅图像采集子窗口的过程催生出了循环结构。然后我们建立起了其与傅立叶分析的联系，这使得我们可以使用快速傅立叶变换（FFT）来快速地整合所有子窗口的信息，而不是通过迭代的方法。<br>These developments enable new learning algorithms that can be orders of magnitude faster than the standard approach. We also show that classification on non-linear feature spaces with the Kernel Trick can be done as efficiently as in the original image space.<br>这些发展使得新的学习算法可以比标准方法快几个数量级。我们还证明，利用核技巧在非线性特征空间进行分类可以和在原始图像空间保持相同的效率。</p>
<h2 id="Previous-work"><a href="#Previous-work" class="headerlink" title="Previous work"></a>Previous work</h2><p>We will briefly discuss tracking-by-detection, but also other works that are relevant to our specific approach.<br>我们将简要讨论检测跟踪方法和与我们的具体方法相关的其他方法。<br>The literature on visual object tracking is extensive, and a full survey is outside the scope of this paper.<sup><a href="#fn_1" id="reffn_1">1</a></sup> Like other works in tracking-by-detection, our contributions are focused on the appearance model, as opposed to the motion model and search strategy. Many use established learning algorithms such as Boosting [6, 3], Support Vector Machines (SVM) [5], or Random Forests [7], and adapt them to online training. Recent works have focused increasingly on problems specific to tracking, such as uncertainty in the training labels. Some notable examples use Semi-Supervised Learning [6] and Multiple Instance Learning [3] (MILTrack) to handle this. Going even further, Hare et al. [4] propose Struck, an online version of Structured Output SVM. This is closer to our work, since the framework allows sample selection over the possible subwindows (argmax step). However, in practice, the number of samples is still limited.<br>视觉目标跟踪的文献很多，进行全面的调查在本文的研究范畴之外。和跟踪检测的其他方法一样，我们的贡献集中于表观模型，而不是运动模型和搜索策略。很多方法都是使用已建立的学习算法，如提升法[6, 3]，支持向量机（SVM）[5]，或随机森林[7]，并将它们调整为在线训练。最近的工作越来越关注跟踪特有的问题，例如训练标签的不确定性。一些著名的例子使用半监督学习[6]和多示例学习[3]（MILTrack）来处理这一问题。更进一步，Hare et al.[4]提出了Struck，一种结构化输出支持向量机的在线版本。这更接近我们的方法，因为这个框架可以在所有可能的子窗口（argmax step）中进行样本选择。然而，在实践中，样本的数量仍然有限。<br>The idea of exploring subwindow redundancy has been noted before, but mostly in the context of detection, not training. Lampert et al. [10] use branch-and-bound optimization to find the maximum of a classier’s response without necessarily evaluating it at all locations. Alexe et al. [11] propose a method that can efficiently find the most similar subwindows between two images, which is a related problem. Although they are useful and provide interesting insights, it may still be desirable to compute the responses at many locations, for example to allow more robust mode seeking or to evaluate the quality of the response [12]. An alternative is to use linear classification in a first stage, and then non-linear classification on promising locations [13, 14], but the results can be suboptimal.<br>探索子窗口冗余的想法之前已经被提出，但主要是在检测的背景下，而不是训练。Lampert et al.[10]使用分支定界优化方法来寻找分类器响应的最大值，而不必在所有位置对其进行评估。Alexe et al.[11]提出了一种能够有效地找到两幅图像之间最相似子窗口的方法，这是一个相关问题。虽然它们是有用的并且提供了有趣的见解，但可能仍然需要在许多位置计算响应，例如允许更鲁棒的模式搜索或评估响应的质量[12]。另一种选择是在第一阶段中使用线性分类器，然后对有前景的位置使用非线性分类器[13, 14]，但其结果可以是次优解。<br>Also closely related are adaptive correlation filters, rooted on classical signal processing [15, 12]. Their response can be evaluated quickly at all subwindows using the Fast Fourier Transform (FFT). It’s possible to perform training on the Fourier domain as well, minimizing the error of the filter’s response at all subwindows of the training images. The crucial detail is that they never actually iterate over the subwindows. The Minimum Output Sum of Squared Error (MOSSE) filter [12] has been shown to be competitive with the methods outlined before, but at a fraction of the complexity, and runs at impressive speeds.<br>植根于经典信号处理的自适应相关滤波器也密切相关[15,12]。它们的响应可以使用快速傅立叶变换（FFT）在所有子窗口中快速评估。也可以在傅立叶域上进行训练，从而最小化训练图像中所有子窗口的滤波器响应的误差。关键细节在于它们实际上并没有迭代子窗口。Minimum Output Sum of Squared Error（MOSSE）滤波器[12]已经表明和前面概述的方法相比具有竞争力，不同的是其并不复杂，并且能够快速运行，给人留下深刻的印象。<br>Because they can be interpreted as linear classifiers, there is the question of whether correlation filters can take advantage of the Kernel Trick to classify on richer non-linear feature spaces. Patnaik and Casasent [16] investigate this problem, and show that, given the Fourier representation of an image, many classical filters cannot be kernelized. Instead, they propose a kernelized filter that is trained with a single subwindow (called Kernel SDF). An ideal solution would implicitly train with all subwindows.<br>因为它们可以被解释为线性分类器，于是存在一个问题，即相关滤波器是否能够利用核技巧在更丰富的非线性特征空间上进行分类。Patnaik and Casasent[16] 研究了这个问题，并且表明，考虑到一张图像的傅立叶表示，许多经典滤波器不能被核化。相反，他们提出了一个核化的滤波器（称为核SDF），其用单个子窗口进行训练。一个理想的解决方案是隐式训练所有子窗口。<br>We believe that the method we propose achieves this goal. We are able to devise Kernel classifiers with the same characteristics as correlation filters, namely their ability to be trained and evaluated quickly with the FFT.<br>我们相信，我们提出的方法能实现这一目标。我们能够设计出具有相关滤波器特征的核分类器，即具有利用FFT来快速训练和评估的能力。</p>
<h2 id="Contributions"><a href="#Contributions" class="headerlink" title="Contributions"></a>Contributions</h2><p>The contributions of this paper are as follows:<br>1.A theoretical framework to study generic classifiers that are trained with all subwindows (of fixed size) of an image.We call this approach dense sampling.<br>2.Proof that the kernel matrix in this case has circulant structure, for unitarily invariant kernels (Theorem 1).<br>3.Closed-form, fast and exact solutions (all running in $\mathcal{O}(n^{2}logn)$ for $n×n$ images) for:<br>  (a) Kernel Regularized Least Squares with dense sampling (Section 2.4).<br>  (b) Detection at all subwindows with generic Kernel classifiers (Section 2.5).<br>  (c) Computation of a variety of kernels at all subwindows, including the popular Gaussian and polynomial kernels     (Section 3).<br>4.Finally, we propose a tracker based on these ideas. We show it is competitive with state-of-the-art trackers, but has a simpler implementation and runs many times faster. Source code is provided.<br>本文的贡献如下：<br>1.一个理论框架，以研究用于训练一张图像的所有子窗口（固定大小）的通用分类器。我们称这种方法为密集采样。<br>2.对于酉不变核，证明了这种情况下的核矩阵具有循环结构（定理1）。<br>3.封闭、快速且精确的解，对于$n×n$图像，时间复杂度为$\mathcal{O}(n^{2}logn)$：<br> （a）使用密集采样的核岭回归（第2.4节）。<br> （b）使用通用核分类器的对所有子窗口进行检测（第2.5节）。<br> （c）在所有子窗口中计算各种核函数，包括流行的高斯核函数和多项式核函数（第3节）。<br>4.最后，我们提出了基于这些理论的跟踪器。我们证明了它能与最先进的跟踪器一教高下，但该跟踪器有一个更简单的实现且运行速度快很多倍。并且提供了源代码。</p>
<h1 id="Learning-with-dense-sampling"><a href="#Learning-with-dense-sampling" class="headerlink" title="Learning with dense sampling"></a>Learning with dense sampling</h1><p>The core component in tracking-by-detection is a classifier. Each frame, a set of samples is collected around the estimated position of the target; samples close to the target are labeled positive and the ones further away are labeled negative. Updating the classifier with these samples allows it to adapt over time. Due to computational constraints, only a handful of random samples are collected [3-7].<br>检测跟踪的核心部分是分类器。对每帧图像，在目标的估计位置周围收集样本集；靠近目标的样本被标记为正，反之被标记为负。使用这些样本更新分类器使得其随时间调整。由于计算的限制，只有少数随机样本被收集[3-7]。<br>We propose a radically different approach. We intend to train a classifier with all samples: we call this dense sampling. Counter to intuition, this allows a more efficient training. The reason is that the kernel matrix in this case becomes highly structured, and we can exploit it to our advantage.<br>我们提出了根本上不同的方法。我们打算用所有样本训练一个分类器：我们称这叫密集采样。与直觉相反，这能够得到更有效的训练。原因是核矩阵在这种情况下变得高度结构化，我们可以利用它来发挥我们的优势。</p>
<h2 id="Regularized-risk-minimization"><a href="#Regularized-risk-minimization" class="headerlink" title="Regularized risk minimization"></a>Regularized risk minimization</h2><p>We start with a general formulation, mostly to introduce notation. Given a set of training patterns and labels $(\mathbf{x}_{1},y_{1}),\ldots,(\mathbf{x}_{m},y_{m})$, a classifier $f(\mathbf{x})$ is trained by finding the parameters that minimize the regularized risk. A linear classier has the form $f(\mathbf{x})=&lt;\mathbf{w},\mathbf{x}&gt; +b$, where $&lt;\cdot,\cdot&gt;$ is the dot product, and the minimization problem is<br>让我们从一个通用公式开始，主要是为了引入符号。给定一组训练数据和标签$(\mathbf{x}_{1},y_{1}),\ldots,(\mathbf{x}_{m},y_{m})$，通过寻找使正则化风险最小的参数来训练分类器$f(\mathbf{x})$。一个线性分类器具有$f(\mathbf{x})=&lt;\mathbf{w},\mathbf{x}&gt; +b$的形式，其中$&lt;\cdot,\cdot&gt;$是点积，且最小化问题是式（1），</p>
<script type="math/tex; mode=display">\min_{\mathbf{w},b}\sum_{i=1}^{m}L(y_{i},f(\mathbf{x}_{i}))+\lambda \left \| \mathbf{w} \right \|^{2},\tag{1}</script><p>where $L(y,f(\mathbf{x}))$ is a loss function, and $\lambda$ controls the amount of regularization<sup><a href="#fn_2" id="reffn_2">2</a></sup>.<br>其中$L(y,f(\mathbf{x}))$是损失函数，$\lambda$控制正则化的程度。<br>This framework includes the popular Support Vector Machine (SVM), which uses the hinge loss $L(y,f(\mathbf{x}))=max(0,1-yf(\mathbf{x}))$. An alternative is Regularized Least Squares (RLS), also known as Ridge Regression, which uses the quadratic loss $L(y,f(\mathbf{x}))=(y-f(\mathbf{x}))^{2}$. It has been shown that, in many practical problems, RLS offers equivalent classification performance to SVM [17].<br>该框架包括流行的支持向量机（SVM），它使用铰链损失$L(y,f(\mathbf{x}))=max(0,1-yf(\mathbf{x}))$。另一种方法是正则化最小二乘法(RLS)，也称为岭回归，它使用平方损失$L(y,f(\mathbf{x}))=(y-f(\mathbf{x}))^{2}$。已经证明，在许多实际问题中，RLS和SVM（17）的分类性能不相上下。<br>It is well known that the Kernel Trick [18] can improve performance further,by allowing classification on a rich high-dimensional feature space. The inputs are mapped to the feature space using $\varphi(\mathbf{x})$, defined by the kernel $\kappa(\mathbf{x},\mathbf{x’})=&lt;\varphi(\mathbf{x}),\varphi(\mathbf{x’})&gt;$. The Representer Theorem [18, p. 89] then states that a solution can be expanded as a linear combination of the inputs: $\mathbf{w}=\sum_{i}\alpha_{i}\varphi(\mathbf{x}_{i})$.<br>众所周知，通过在丰富的高维特征空间上进行分类，核技巧可以进一步改善性能。输入通过$\varphi(\mathbf{x})$被映射到特征空间，核函数定义为$\kappa(\mathbf{x},\mathbf{x’})=&lt;\varphi(\mathbf{x}), \varphi(\mathbf{x’})&gt;$。表示定理[18, p. 89 ]证明解可以被扩展为输入的线性组合：$\mathbf{w}=\sum_{i}\alpha_{i}\varphi(\mathbf{x}_{i})$。</p>
<blockquote>
<p><strong>Representer Theorem的简单证明</strong><br>假设最优解$w_{✳}=w_{\parallel}+w_{\perp}$，其中$w_{\parallel }$和$w_{\perp}$分别表示平行$\varphi(\mathbf{x})$空间和垂直$\varphi(\mathbf{x})$空间的分量，需要证明的是$w_{\perp}=0$，因为此时$w_{✳}$只含有平行$\varphi(\mathbf{x})$空间的分量，这说明$w_{✳}$可以由$\varphi(\mathbf{x})$线性表示。使用反证法：假设$w_{\perp}\neq0$，比较$w_{✳}$和$w_{\parallel }$。对于式(1)的第一项：  </p>
<script type="math/tex; mode=display">L(y_{i},f(\mathbf{x}_{i}))\overset{\mathbf{x}_{i}\rightarrow\varphi(\mathbf{x}_{i})}{=}L(y_{i},w_{✳}^{T}\varphi(\mathbf{x}_{i}))=L(y_{i},(w_{\parallel }+w_{\perp})^{T}\varphi(\mathbf{x}_{i}))=L(y_{i},w_{\parallel }^{T}\varphi(\mathbf{x}_{i}))</script><p>则第一项是相等的。对于式（1）的第二项：  </p>
<script type="math/tex; mode=display">w_{✳}^{T}w_{✳}=w_{\parallel }^{T}w_{\parallel }+2w_{\parallel }^{T}w_{\perp}+w_{\perp}^{T}w_{\perp}>w_{\parallel }^{T}w_{\parallel }</script><p>与$w_{✳}$是最优解矛盾，故$w_{\perp}=0$。<br>所以求解$w_{✳}$就相当于求解线性组合系数$\boldsymbol{\alpha}$。</p>
</blockquote>
<p>Then, RLS with Kernels (KRLS) has the simple closed form solution [17].<br>于是，核岭回归（KRLS）具有简单的闭式解[17]。  </p>
<script type="math/tex; mode=display">\boldsymbol{\alpha}=(K+\lambda I)^{-1}\mathbf{y} ,\tag{2}</script><p>where $K$ is the kernel matrix with elements $K_{ij}=\kappa(\mathbf{x}_{i},\mathbf{x}_{j})$, $I$ is the identity matrix, and the vector $\mathbf{y}$ has elements $y_{i}$. The solution $\mathbf{w}$ is implicitly represented by the vector $\boldsymbol{\alpha}$, whose elements are the coefficients $\alpha_{i}$. We will show that the matrix inversion in Eq. 2 can be avoided entirely for our purposes.<br>其中$K$是元素为$K_{ij}=\kappa(\mathbf{x}_{i},\mathbf{x}_{j})$的核矩阵，$I$是单位阵，向量$\mathbf{y}$的元素为$y_{i}$。解$\mathbf{w}$可通过向量$\boldsymbol{\alpha}$隐式表示，$\boldsymbol{\alpha}$的元素为$\alpha_{i}$。我们将证明式（2）中的矩阵求逆可以完全避免也能达到我们的目的。</p>
<blockquote>
<p>对于式（2）<br><br><script type="math/tex">\sum_{i=1}^{m}L(y_{i},f(\mathbf{x}_{i}))=\sum_{i=1}^{m}(y_{i}-f(\mathbf{x}_{i}))^{2}\overset{vectorization}{=}(\mathbf{y}-<\mathbf{w},\mathbf{x}>)^{2}\overset{\mathbf{x}\rightarrow\varphi(\mathbf{x})}{=}(\mathbf{y}-<\sum_{i}\alpha_{i}\varphi(\mathbf{x}_{i}),\varphi(\mathbf{x})>)^{2}</script><br>$=(\mathbf{y}-&lt;\sum_{i}\alpha_{i}\varphi(\mathbf{x}_{i}),\sum_{j}\varphi(\mathbf{x}_{j})&gt;)^{2}=(\mathbf{y}-\boldsymbol{\alpha}K)^{2}$<br>由上式可以看出$\mathbf{w}$可以表示为$\varphi(\mathbf{x})$的线性组合是核技巧得以广泛应用的关键。它使得将高维空间的内积转换到低维空间中比较容易计算的函数的内积成为可能。  </p>
<script type="math/tex; mode=display">\left \| \mathbf{w} \right \|^{2}=\mathbf{w}^{T}\mathbf{w}=(\sum_{i}\alpha_{i}\varphi(\mathbf{x}_{i}))(\sum_{j}\alpha_{j}\varphi(\mathbf{x}_{j}))=\boldsymbol{\alpha}^{T}K\boldsymbol{\alpha}</script><p>则式（1）可化为</p>
<script type="math/tex; mode=display">\min_{\boldsymbol{\alpha }}[(\mathbf{y}-\boldsymbol{\alpha}K)^{T}(\mathbf{y}-\boldsymbol{\alpha}K)+\lambda \boldsymbol{\alpha}^{T}K\boldsymbol{\alpha}]</script><p>对上式关于$\boldsymbol{\alpha}$求导并令其为零即可求得式（2）</p>
</blockquote>
<h2 id="Circulant-matrices"><a href="#Circulant-matrices" class="headerlink" title="Circulant matrices"></a>Circulant matrices</h2><p>The main observation that will allow efficient learning is that, under suitable conditions, the kernel matrix becomes $circulant$. An $n×n$ circulant matrix $C(\mathbf{u})$ is obtained from the $n×1$ vector $\mathbf{u}$ by concatenating all possible cyclic shifts of $\mathbf{u}$:<br>使得能够高效学习的主要观察是，在适当的条件下，核矩阵是<strong>循环的</strong>。一个$n×n$循环矩阵$C(\mathbf{u})$是通过连接$n×1$向量$\mathbf{u}$所有可能的循环移位得到的：  </p>
<script type="math/tex; mode=display">C(\mathbf{u})=\begin{bmatrix}
u_{0} &  u_{1}&  u_{2}&  \cdots &u_{n-1} \\ 
 u_{n-1}&  u_{0}&  u_{1}&  \cdots& u_{n-2}\\ 
 u_{n-2}&  u_{n-1}&  u_{0}&  \cdots& u_{n-3}\\ 
 \vdots & \vdots &  \vdots& \ddots  & \vdots\\ 
 u_{1}&  u_{2}&  u_{3}&  \cdots& u_{0}
\end{bmatrix}.\tag{3}</script><p>The first row is vector $\mathbf{u}$, the second row is $\mathbf{u}$ shifted one element to the right (the last element wraps around), and so on.<br>第一行是向量$\mathbf{u}$，第二行是$\mathbf{u}$向右移动一个元素（最后一个元素环绕），依此类推。<br>The motivation behind circulant matrices is that they encode the convolution of vectors, which is conceptually close to what we do when evaluating a classifier at many different subwindows. Since the product $C(\mathbf{u})\mathbf{v}$ represents convolution of vectors $\mathbf{u}$ and $\mathbf{v}$ [19], it can be computed in the Fourier domain, using<br>循环矩阵背后的动机是它们编码了向量的卷积，这在概念上很接近我们使用许多不同的子窗口去评估一个分类器时所做的。由于乘积$C(\mathbf{u})\mathbf{v}$表示向量$\mathbf{u}$和$\mathbf{v}$的卷积[19]，所以它可以在傅立叶域中进行计算，使用  </p>
<script type="math/tex; mode=display">C(\mathbf{u})\mathbf{v}=\mathcal{F}^{-1}(\mathcal{F}^{*}(\mathbf{u})\odot \mathcal{F}(\mathbf{v})),\tag{4}</script><p>where $\odot$ is the element-wise product, while $\mathcal{F}$ and $\mathcal{F^{-1}}$ denote the Fourier transform and its inverse, respectively, and $^{\ast}$ is the complex-conjugate.<br>其中$\odot$为点积，$\mathcal{F}$和$\mathcal{F}^{-1}$分别表示傅里叶变换及其逆变换，$^{\ast}$表示复共轭。<br>The properties of circulant matrices make them particularly amenable to manipulation, since their sums, products and inverses are also circulant [19]. We never have to explicitly compute and store a circulant matrix $C(\mathbf{u})$, because it is defined by $\mathbf{u}$. These operations often involve the Fourier Transform of $\mathbf{u}$.<br>循环矩阵的性质使得它们特别易于操作，因为它们的和、积和逆也是循环矩阵[19]。我们从来不需要显式地计算和存储循环矩阵$C(\mathbf{u})$，因为它能被$\mathbf{u}$定义。这些操作通常涉及$\mathbf{u}$的傅里叶变换。<br>There are a couple of different definitions of $C(\mathbf{u})$ that we will find useful[19]. One is that the row $i$ of $C(\mathbf{u})$ is given by $P^{i}\mathbf{u}$, where $P$ is the permutation matrix that cyclically shifts $\mathbf{u}$ by one element. The matrix power in $P^{i}$ applies the permutation $i$ times, resulting in $i$ cyclic shifts.<br>$C(\mathbf{u})$有几种不同的定义方式，我们将会发现它们很有用[19]。其中之一是$C(\mathbf{u})$的第$i$行可由$P^{i}\mathbf{u}$表示，其中$P$是使$\mathbf{u}$循环移位一个元素的置换矩阵。矩阵幂$P^{i}$应用了$i$次置换，会导致$i$次循环移位。<br>Alternatively, the elements of $C(\mathbf{u})$ can be defined as $c_{ij} = u_{(j-i)\ mod\ n}$. That is, a matrix is circulant if its elements only depend on $(j-i)$ mod $n$, where mod is the modulus operation (remainder of division by $n$). To make some derivations easier, all indexes are zero-based.<br>另外，$C(\mathbf{u})$中的元素可以定义为$c_{ij} = u_{(j-i)\ mod\ n}$。也就是说，一个矩阵是循环的如果它的元素仅取决于$(j-i)$ mod $n$，其中mod是取模运算（除以$n$后的余数）。为了使一些推导更容易，所有索引都是从零开始。</p>
<h2 id="The-kernel-matrix-with-dense-sampling"><a href="#The-kernel-matrix-with-dense-sampling" class="headerlink" title="The kernel matrix with dense sampling"></a>The kernel matrix with dense sampling</h2><p>We introduce the concept of dense sampling. For a matter of clarity, we start with one-dimensional images with a single feature (ie., the pixel value). This allows more intuitive proofs with simpler notation. However, they are readily transferable to the case of 2D images with multiple channels, such as RGB images, and dense SIFT or HOG descriptors. Appendix A.3 presents more details.<br>我们介绍密集采样的概念。为了明晰起见，我们从具有一个单一特征（比如像素值）的一维图像开始。这样可以使用更简单的符号进行更直观的证明。然而，它们很容易推广到具有多通道的2D图像，比如RGB图像和稠密SIFT特征描述子或HOG特征描述子。附录A.3给出了更多的细节。<br>Given a single image $\mathbf{x}$, expressed as a $n×1$ vector, the samples are defined as<br>给定一个图像$\mathbf{x}$，表示为一个$n×1$向量，样本被定义为  </p>
<script type="math/tex; mode=display">\mathbf{x}_{i}=P^{i}\mathbf{x},\forall i=0,\ldots,n-1\tag{5}</script><p>with $P$ the permutation matrix that cyclically shifts vectors by one element, as defined earlier. Intuitively, the samples are all possible translated versions of $\mathbf{x}$ (except at the boundaries, discussed in Section 4.1). We will now prove that the resulting kernel matrix is circulant, and show under what conditions.<br>使用置换矩阵$P$循环位移向量一个元素，如先前定义那般。直观地说，样本集是$\mathbf{x}$所有可能的移位（除了在第4.1节中讨论的边界）。现在我们将证明所得到的核矩阵是循环矩阵，并且说明其适用条件。<br><strong>Theorem 1.</strong> The matrix $K$ with elements $K_{ij}=\kappa (P^{i}\mathbf{x},P^{j}\mathbf{x})$ is circulant if $\kappa$ is a unitarily invariant kernel.<br><strong>定理1。</strong> 如果$\kappa$是酉不变核，元素为$K_{ij}=\kappa(P^{i}\mathbf{x},P^{j}\mathbf{x})$的矩阵$K$是循环矩阵。<br>$Proof.$ A kernel $\kappa$ is unitarily invariant if $\kappa (\mathbf{x},\mathbf{x’}) = \kappa (U\mathbf{x},U\mathbf{x’})$ for any unitary matrix $U$. Since permutation matrices are unitary, $K_{ij} =\kappa (P^{i}\mathbf{x},P^{j}\mathbf{x})=\kappa (P^{-i}P^{i}\mathbf{x},P^{-i}P^{j}\mathbf{x}) $. Because $K_{ij}$ depends only on $(j-i)$ mod $n$, $K$ is circulant.<br>证明。一个核函数$\kappa$是酉不变的如果$\kappa (\mathbf{x},\mathbf{x’}) = \kappa (U\mathbf{x},U\mathbf{x’})$ 对任意酉矩阵$U$都成立。因为转置矩阵是酉矩阵，所以有$K_{ij} =\kappa (P^{i}\mathbf{x},P^{j}\mathbf{x})=\kappa (P^{-i}P^{i}\mathbf{x},P^{-i}P^{j}\mathbf{x}) $。因为$K_{ij}$只取决于$(j-i)$ mod $n$，故$K$是循环矩阵。<br><strong>Corollary 1.</strong> $K$ as defined above is circulant for dot-product and radial basis function kernels. Particular examples are the polynomial and Gaussian kernel.<br><strong>推论1。</strong> 对点积核函数和径向基核函数来说，如上定义的$K$是循环矩阵。特别的例子是多项式核和高斯核。<br>This is an important property that allows the creation of efficient learning algorithms.We will now focus on applying this knowledge to KRLS.<br>这是一个重要的属性，它能够创造高效的学习算法。现在我们将专注于在核岭回归中应用这个知识。</p>
<h2 id="Efficient-Kernel-Regularized-Least-Squares-solution"><a href="#Efficient-Kernel-Regularized-Least-Squares-solution" class="headerlink" title="Efficient Kernel Regularized Least Squares solution"></a>Efficient Kernel Regularized Least Squares solution</h2><p>Theorem 1 is readily applicable to KRLS. We will define vector $\mathbf{k}$ with elements<br>定理1很容易应用于核岭回归。我们将用式（6）的元素来定义向量$\mathbf{k}$</p>
<script type="math/tex; mode=display">k_{i} =\kappa(\mathbf{x},P^{i}\mathbf{x}),\forall i=0,\ldots,n-1\tag{6}</script><p>which compactly represents the kernel matrix $K=C(\mathbf{k})$. Notice that $\mathbf{k}$ is only $n×1$, while the full $K$ would be $n×n$.<br>它紧凑地表示了核矩阵$K=C(\mathbf{k})$。注意$\mathbf{k}$仅为$n×1$，而整个矩阵$K$为$n×n$。<br>Some operations on matrices of the form $C(\mathbf{u})$, like multiplication and inversion, can be done element-wise on the vectors $\mathbf{u}$, if they are transformed to the Fourier domain [19].<br>对$C(\mathbf{u})$形式的矩阵进行的一些运算，如乘积和求逆，如果把它们变换到傅里叶域[19]，则可以在向量$\mathbf{u}$上进行逐元素运算。<br>By applying these properties to Eq. 2 and Eq. 6, we obtain the KRLS solution:<br>通过将这些性质应用到式（2）和式（6），我们得到核岭回归的解：  </p>
<script type="math/tex; mode=display">\boldsymbol{\alpha }=\mathcal{F}^{-1}(\frac{\mathcal{F}(\mathbf{y})}{\mathcal{F}(\mathbf{k})+\lambda }),\tag{7}</script><p>where the division is performed element-wise. A detailed proof is in Appendix A.1.<br>其中除法是逐元素执行的。详细的证明见附录A.1。<br>Note that the vector $\boldsymbol{\alpha }$ contains all the $\alpha_{i}$ coefficients. This closed-form solution is very efficient: it uses only Fast Fourier Transform (FFT) and element-wise operations.We’ll see in Sec. 3 that $\mathbf{k}$ can also be computed quickly with the FFT.<br>注意到向量$\boldsymbol{\alpha }$包含所有$\alpha_{i}$系数。这种解析解非常高效：它只使用快速傅立叶变换（FFT）和逐元素运算。我们将在第3节看到$\mathbf{k}$也可以使用FFT进行快速计算。<br>For $n×n$ images, the proposed algorithm has a complexity of only $\mathcal{O}(n^{2}logn)$, while a naive KRLS implementation would take $\mathcal{O}(n^{4})$ operations. This is done without reducing the number of samples, which would sacrifice performance.<br>对于$n×n$图像，所提出的算法只有$\mathcal{O}(n^{2}logn)$的复杂度，而原始核岭回归的实现将耗费$\mathcal{O}(n^{4})$复杂度的运算。这是在不减少样本数量的情况下进行的，这将不会牺牲性能。</p>
<h2 id="Fast-detection"><a href="#Fast-detection" class="headerlink" title="Fast detection"></a>Fast detection</h2><p>The general formula for computing the classifier response for a single input $\mathbf{z}$ is<br>计算单一输入$\mathbf{z}$的分类器响应的通用公式是  </p>
<script type="math/tex; mode=display">y'=\sum_{i}^{ }\alpha _{i}\kappa (\mathbf{x}_{i},\mathbf{z}).\tag{8}</script><p>This formula is typically evaluated at all subwindows, in a sliding-window manner. However, we can exploit the circulant structure to compute all the responses simultaneously and efficiently. Using the properties discussed earlier, the vector with the responses at $all$ positions is given by<br>该公式通常以滑动窗口的方式在所有子窗口中进行评估。然而，我们可以利用循环结构同时并高效地计算所有响应。使用前面所讨论的特性，具有<strong>所有</strong>位置的响应的向量由式（9）给出</p>
<script type="math/tex; mode=display">\hat{\mathbf{y}}=\mathcal{F}^{-1}(\mathcal{F}(\bar{\mathbf{k}})\odot\mathcal{F}(\boldsymbol{\alpha})),\tag{9}</script><p>where $\bar{\mathbf{k}}$ is the vector with elements $\bar{k}_{i} =\kappa(\mathbf{z},P^{i}\mathbf{x})$. We provide an extended proof in Appendix A.2. Just like the formula for KRLS training, the complexity is bound by the FFT operations and is only $\mathcal{O}(n^{2}logn)$ for 2D images.<br>其中$\bar{\mathbf{k}}$是元素为$\bar{k}_{i} =\kappa(\mathbf{z},P^{i}\mathbf{x})$的向量。我们在附录A.2中提供了扩展证明。就像核岭回归的训练公式一样，受到FFT运算的约束，对于2D图像其复杂度仅为$\mathcal{O}(n^{2}logn)$。</p>
<h1 id="Fast-computation-of-non-linear-kernels"><a href="#Fast-computation-of-non-linear-kernels" class="headerlink" title="Fast computation of non-linear kernels"></a>Fast computation of non-linear kernels</h1><p>The proposed training procedure is fast, but the question of how to evaluate nonlinear kernels quickly for all subwindows (ie., compute $\mathbf{k}$ and $\bar{\mathbf{k}}$) still remains. As of this writing, this is a topic of active research [10, 11, 16].<br>所提出的训练过程很快，但是如何快速计算所有子窗口的非线性核（如计算$\mathbf{k}$和$\bar{\mathbf{k}}$）的问题仍然存在。在撰写本文时，这是一个积极研究的主题[10,11,16]。<br>Linear kernels are usually preferred in time-critical problems such as tracking, because the weights vector $\mathbf{w}$ can be computed explicitly. Non-linear kernels require iterating over all samples (or support vectors). The work that comes closest to the goal of efficiently computing non-linear kernels at all locations is by Patnaik [20]. Unfortunately, it requires inputs that have unit norm, and the normalization may discard important information.<br>线性核函数通常在实时性要求高的问题（如跟踪）中是首选，因为权重向量$\mathbf{w}$可以显式计算。 非线性核函数需要迭代所有样本（或支持向量）。最接近于在所有位置高效计算非线性核函数的目标的工作成果是Patnaik[20]。不幸的是，它需要归一化后的输入，并且归一化可能会丢失重要信息。<br>In this work, we propose closed-form solutions to compute a variety of kernels at all image locations, in an efficient manner that fully exploits the problem structure. The formulas are exact, and simple to compute.<br>在本文中，以一种充分利用问题结构的高效形式，我们提出了在所有图像位置计算各种核函数的解析解。该公式是精确的，并且易于计算。</p>
<h2 id="Dot-product-kernels"><a href="#Dot-product-kernels" class="headerlink" title="Dot-product kernels"></a>Dot-product kernels</h2><p>Dot-product kernels have the form $\kappa (\mathbf{x},\mathbf{x’})=g (&lt;\mathbf{x},\mathbf{x’}&gt;)$, for some function $g$. In this case, the compact representation $\mathbf{k}$ of the kernel matrix (Eq. 6) will be denoted by $\mathbf{k}^{dp}$. Each element of $\mathbf{k}^{dp}$ is given by<br>对于某些函数$g$，点积核函数具有$\kappa (\mathbf{x},\mathbf{x’})=g (&lt;\mathbf{x},\mathbf{x’}&gt;)$的形式。在这种情况下，核矩阵（式（6））的紧凑表示$\mathbf{k}$将由$\mathbf{k}^{dp}$表示。$\mathbf{k}^{dp}$的每个元素由式（10）给出  </p>
<script type="math/tex; mode=display">k_{i}^{dp}=\kappa (\mathbf{x},P^{i}\mathbf{x'})=g(\mathbf{x}^{T}P^{i}\mathbf{x'}).\tag{10}</script><p>With slight abuse of notation, we will say that $g$ can also be applied element-wise to an input vector, so $\mathbf{k}^{dp}$ can be written as $\mathbf{k}^{dp}=g(C(\mathbf{x’})\mathbf{x})$.<br>稍微滥用下符号，我们可以说$g$也可以逐元素地应用于输入向量，因此$\mathbf{k}^{dp}$可以写成$\mathbf{k}^{dp}=g(C(\mathbf{x’})\mathbf{x})$。</p>
<blockquote>
<p>见补充材料性质3</p>
</blockquote>
<p>Using the convolution property from Eq. 4, we obtain the solution<br>使用式（4）的卷积性质，我们得到该解  </p>
<script type="math/tex; mode=display">\mathbf{k}^{dp}=g(\mathcal{F}^{-1}(\mathcal{F}(\mathbf{x})\odot\mathcal{F}^{*}(\mathbf{x'}))).\tag{11}</script><p>Eq. 11 means that a dot-product kernel can be quickly evaluated at all image locations, using only a few FFT and element-wise operations. In particular, for a polynomial kernel,<br>式（11）意味着使用一些FFT和逐元素运算就可以在所有图像位置快速计算一个点积核。特别地，对于一个多项式核，</p>
<script type="math/tex; mode=display">\mathbf{k}^{poly}=(\mathcal{F}^{-1}(\mathcal{F}(\mathbf{x})\odot\mathcal{F}^{*}(\mathbf{x'}))+c)^{d}.\tag{12}</script><h2 id="Radial-Basis-Function-kernels"><a href="#Radial-Basis-Function-kernels" class="headerlink" title="Radial Basis Function kernels"></a>Radial Basis Function kernels</h2><p>RBF kernels have the form $\kappa (\mathbf{x},\mathbf{x’})=h(\left | \mathbf{x}-\mathbf{x’} \right |^2)$, for some function $h$. The corresponding $\mathbf{k}$ from Eq. 6 will be denoted by $\mathbf{k}^{rbf}$.<br>对于某些函数$h$，径向基核函数具有$\kappa (\mathbf{x},\mathbf{x’})=h(\left | \mathbf{x}-\mathbf{x’} \right |^2)$的形式。式（6）中对应的$\mathbf{k}$将由$\mathbf{k}^{rbf}$表示。  </p>
<script type="math/tex; mode=display">k_{i}^{rbf}=\kappa (\mathbf{x},P^{i}\mathbf{x'})=h(\left \| \mathbf{x}-P^{i}\mathbf{x'} \right \|^2)\tag{13}</script><p>We can expand the norm, obtaining<br>我们可以将范数展开，得到  </p>
<script type="math/tex; mode=display">k_{i}^{rbf}=h(\left \| \mathbf{x}\right \|^2+\left \| \mathbf{x'}\right \|^2-2\mathbf{x}^{T}P^{i}\mathbf{x'}).\tag{14}</script><p>The permutation $P^{i}$ doesn’t affect the norm of $\mathbf{x’}$ due to Parseval’s identity.<br>根据帕舍伐尔恒等式，转置矩阵$P^{i}$不会影响$\mathbf{x’}$范数。<br>Since $\left | \mathbf{x}\right |^2$ and $\left | \mathbf{x’}\right |^2$ are constant w.r.t. $i$, Eq. 14 is in the same form as for dot-product kernels. Following the same derivation as in Section 3.1, we arrive at the general solution for RBF kernels<br>因为$\left | \mathbf{x}\right |^2$和$\left | \mathbf{x’}\right |^2$是关于$i$的常数，则式（14）具有和点积核相同的形式。按照3.1节中的推导，我们可以得出径向基核的通用解</p>
<script type="math/tex; mode=display">\mathbf{k}^{rbf}=h(\left \| \mathbf{x}\right \|^2+\left \| \mathbf{x'}\right \|^2-2\mathcal{F}^{-1}(\mathcal{F}(\mathbf{x})\odot\mathcal{F}^{*}(\mathbf{x'}))).\tag{15}</script><p>In particular, we have, for the Gaussian kernel,<br>特别地，对于高斯核，我们有，</p>
<script type="math/tex; mode=display">\mathbf{k}^{gauss}=exp(-\frac{1}{\sigma ^2}(\left \| \mathbf{x}\right \|^2+\left \| \mathbf{x'}\right \|^2-2\mathcal{F}^{-1}(\mathcal{F}(\mathbf{x})\odot\mathcal{F}^{*}(\mathbf{x'}))))\tag{16}.</script><p>For an $n×n$ image, direct kernel computation at $n^2$ locations would take $\mathcal{O}(n^4)$ operations, however the corresponding frequency-domain solution brings this complexity down to only $\mathcal{O}(n^2logn)$.<br>对于一张$n×n$图像，在$n^2$个位置直接进行核函数计算将花费复杂度为$\mathcal{O}(n^4)$的运算，但是其对应的频域解析解将复杂度降低到仅为$\mathcal{O}(n^2logn)$。<br>The generic formulas we derived for each kernel will quickly compute the $\mathbf{k}$ and $\bar{\mathbf{k}}$ terms in KRLS training (Eq. 7) and detection (Eq. 9). We expect them to be of general interest, however, and be useful for other kernel methods.<br>我们为每个核推导出的通用公式能快速计算岭回归训练（式（7））和检测（（式9））中的$\mathbf{k}$和$\bar{\mathbf{k}}$项。然而，我们期望它们具有普遍意义，并且对其他核方法也适用。</p>
<h2 id="The-linear-case"><a href="#The-linear-case" class="headerlink" title="The linear case"></a>The linear case</h2><p>The simplest kernel function, $\kappa (\mathbf{x},\mathbf{x’})=&lt;\mathbf{x},\mathbf{x’}&gt;$, which is just the dot-product in the original space, is worth investigating. It produces a linear classifier that does not make use of the Kernel Trick, so we can compute $\mathbf{w}$ explicitly, instead of implicitly as $\boldsymbol{\alpha}$. Plugging it into the KRLS equations, we obtain:<br>最简单的核函数是$\kappa (\mathbf{x},\mathbf{x’})=&lt;\mathbf{x},\mathbf{x’}&gt;$，它只是原始空间中的点积，其值得研究。它可以产生一个不使用核技巧的线性分类器，因此我们可以显式地计算$\mathbf{w}$，而不是隐式地计算$\boldsymbol{\alpha}$。将其代入核岭回归方程，我们得到：  </p>
<script type="math/tex; mode=display">\mathbf{w}=\mathcal{F}^{-1}(\frac{\mathcal{F}(\mathbf{x})\odot\mathcal{F}^{*}(\mathbf{y})}{\mathcal{F}(\mathbf{x})\odot\mathcal{F}^{*}(\mathbf{x})+\lambda}).\tag{17}</script><p>This is a kind of correlation filter that has been proposed recently, called Minimum Output Sum of Squared Error (MOSSE) [12, 15], with a single training image. It is remarkably powerful despite its simplicity.<br>这是最近提出的一种相关滤波器，称为Minimum Output Sum of Squared Error（MOSSE）[12,15]，使用一幅图像进行训练。它非常强大尽管很简单。<br>Note, however, that correlation filters are obtained with classical signal processing techniques, directly in the Fourier domain. As we have shown, Circulant matrices are the key enabling factor to extend them with the Kernel Trick.<br>然而，请注意，相关滤波器是直接在傅立叶域中使用经典信号处理技术获得的。如前所示，循环矩阵是使用核技巧扩展它们的关键促成因素。</p>
<h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><p>We used the techniques described above to implement a simple tracking system. Many obvious improvements, like failure detection, motion and uncertainty models (eg., particle filter), or feature extraction, were deliberately left out. This was done to reduce the confounding factors to a minimum, and provide an accurate validation of the learning algorithm.<br>我们使用上述技术来实现一个简单跟踪系统。许多明显的改进被故意省略不提，例如跟踪失败检测，运动和不确定模型（例如粒子滤波器）和特征提取。这样做是为了将混淆因素降至最低，并提供学习算法的精确验证。<br>From now on, we will assume two-dimensional images. A thorough proof is given in Appendix A.3. In practice it means that the 2D Fourier transform can replace the 1D FT in all the previous equations.<br>从现在开始，我们将假定使用二维图像。附录A.3给出了彻底的证明。这意味着在实践中二维傅立叶变换可以替代所有先前等式中的一维傅立叶变换。</p>
<h2 id="Pre-processing"><a href="#Pre-processing" class="headerlink" title="Pre-processing"></a>Pre-processing</h2><p>The proposed method can operate directly on the pixel values, with no feature extraction. However, since the Fourier transform is periodic, it does not respect the image boundaries. The large discontinuity between opposite edges of a nonperiodic image will result in a noisy Fourier representation. A common solution is to band the original $n×n$ image ($x^{raw}$) with a cosine (or sine) window:<br>所提出的方法可以直接对像素值进行操作，而不进行特征提取。然而，由于傅立叶变换是周期性的，因此它不注重图像边界。一张非周期性图像的相反边缘间强烈的不连续性将导致嘈杂的傅立叶表示。一种常见的解决方法是对原始的$n×n$图像($x^{raw}$)加上一个余弦（或正弦）窗：  </p>
<script type="math/tex; mode=display">x_{ij}=(x_{ij}^{raw}-0.5)sin(\pi i/n)sin(\pi j/n),\forall i,j=0,\ldots,n-1\tag{18}</script><p>Values near the borders will be weighted to zero, eliminating discontinuities.<br>边界附近的值将加权为零，从而消除不连续性。</p>
<h2 id="Training-outputs"><a href="#Training-outputs" class="headerlink" title="Training outputs"></a>Training outputs</h2><p>During training, we must assign a label to each sample. In tracking-by-detection, samples near the target center are positive and others are negative. But since the square loss of KRLS allows for continuous values, we don’t need to limit ourselves to binary labels. The line between classification (binary output) and regression (continuous output) is essentially blurred.<br>在训练期间，我们必须为每个样本分配标签。在检测跟踪中，目标中心附近的样本是正样本，其它样本是负样本。但由于核岭回归使用的平方损失允许连续值，我们不需要拘泥于只使用二类标签。分类（二类值输出）和回归（连续值输出）之间的界限基本上是模糊的。<br>Given the choice of a continuous training output, we will use a Gaussian function, which is known to minimize ringing in the Fourier domain [21]. The output will be 1 near the target location $(i’$,$ j’)$, and decay to 0 as the distance increases, with a bandwidth of $s$:<br>鉴于使用连续的训练输出值的选择，我们将使用高斯函数，其可以最小化傅立叶域中的振铃[21]。在目标位置$(i’$,$ j’)$附近的输出值接近为1，并且随着距离的增加衰减到0，使用的带宽为$s$：  </p>
<script type="math/tex; mode=display">y_{ij}=exp(-((i-i')^2+(j-j')^2)/s^2),\forall i,j=0,\ldots,n-1\tag{19}</script><p>The continuous labeling yields spatially smooth classifier responses, which results in more accurate position estimates than binary labeling (Table 2).<br>连续值标签产生的是空间平滑的分类器响应，这导致了比使用二类值标签更精确的位置估计（表2）。</p>
<h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>The tracker follows a simple pipeline. A window of a fixed size (double the target size) is cropped from the input image, at the estimated target location. No feature extraction is performed, other than a cosine window on the raw pixel values (Eq. 18). The target is located by evaluating Eq. 9 and finding the maximum response. Eq. 7 is then used to train a new model ($\boldsymbol{\alpha}$ and $\mathbf{x}$).<br>跟踪器遵循一个简单的流程。在估计的目标位置处，从输入图像裁剪固定大小（目标大小的两倍）的窗口。除了在原始像素值上使用余弦窗（式（18））之外，不进行其它特征提取操作。通过计算式（9）并找到最大响应值来定位目标。然后使用式（7）来训练一个新的模型（$\boldsymbol{\alpha}$和$\mathbf{x}$）。<br>To provide some memory, the new model is integrated by linearly interpolating the new parameters with the ones from the previous frame. We found that this scheme, adapted from the work of Bolme et al. [12], is enough for our purposes. Future work will explore other ways to aggregate samples over time.<br>为提供一些记忆性，新模型通过将新参数和前一帧中的参数进行线性插值来集成。我们发现这个改编自Bolme et al.[12]的工作的方案，足以满足我们的目的。未来的工作将探索其他方法来随时间推移聚合样本。</p>
<h2 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h2><h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>We presented a theoretical framework to analyze and explore the consequences of dense sampling in tracking-by-detection. The result is a collection of closed form, fast and exact solutions for online training, detection, and computation of non-linear kernels. We expect this last contribution to find useful applications outside of tracking. We also hope to have shown that some structures that occur naturally in computer vision, such as Circulants, are still relatively unexplored.<br>我们提出了一个理论框架来分析和探索在检测跟踪中密集采样的结果。其结果是一系列用于在线训练，检测和计算非线性核的快速而精确的解析解。我们期望最后的贡献是能够在跟踪之外得到有用的应用。我们也希望证明了在计算机视觉中自然出现的一些结构，例如循环结构，相对而言仍然是一种未开发状态。</p>
<h1 id="Appendix-A-1-Dense-Sampling-KRLS-derivation"><a href="#Appendix-A-1-Dense-Sampling-KRLS-derivation" class="headerlink" title="Appendix A.1: Dense Sampling KRLS derivation"></a>Appendix A.1: Dense Sampling KRLS derivation</h1><p>We will use the fact that $K$ is circulant, replacing Eq. 6 in the generic KRLS solution of Eq. 2. Observing that any identity matrix $I$ is circulant, $I=C(\boldsymbol{\delta})$ with $\boldsymbol{\delta}=\left [1,0,0,\ldots,0  \right ]^T$, Eq. 2 becomes<br>我们将使用$K$是循环矩阵的事实，替换通用核岭回归解（式（2））中的式（6）。观察到任何单位矩阵$I$都是循环矩阵，$I=C(\boldsymbol{\delta})$，其中$\boldsymbol{\delta}=\left [1,0,0,\ldots,0  \right ]^T$，式（2）变成</p>
<script type="math/tex; mode=display">\boldsymbol{\alpha}=(C(\mathbf{k})+\lambda C(\boldsymbol{\delta}))^{-1}\mathbf{y}=(C(\mathbf{k}+\lambda \boldsymbol{\delta}))^{-1}\mathbf{y}.\tag{20}</script><p>The properties of circulant matrices allow element-wise multiplication and inversion in the Fourier domain [19]. Making use of these properties, and the fact that $F(\boldsymbol{\delta})=\mathbf{1}$, where $\mathbf{1}$ is an $n×1$ vector of ones,<br>循环矩阵具有能在傅立叶域中逐元素相乘和求逆的性质[19]。利用这些性质，以及$F(\boldsymbol{\delta})=\mathbf{1}$的事实，其中$\mathbf{1}$是一个全为1的$n×1$向量，</p>
<script type="math/tex; mode=display">\boldsymbol{\alpha}=(C(\mathcal{F}^{-1}(\mathcal{F}(\mathbf{k})+\lambda\mathbf{1})))^{-1}\mathbf{y}=C(\mathcal{F}^{-1}(\frac{1}{\mathcal{F}(\mathbf{k})+\lambda}))\mathbf{y}.\tag{21}</script><blockquote>
<p>循环矩阵有如下性质：</p>
<script type="math/tex; mode=display">X^{-1}=C(\mathbf{x})^{-1}=Fdiag(\hat{\mathbf{x}})^{-1}F^H=Fdiag(\hat{\mathbf{x}}^{-1})F^H=C(\mathcal{F}^{-1}(\hat{\mathbf{x}}^{-1}))</script><p>其中$F$是离散傅里叶矩阵，$\hat{\mathbf{x}}=\mathcal{F}(\mathbf{x})$，$X$的特征值是$\hat{\mathbf{x}}$的元素。于是式（20）可以直接推导为$C(\mathcal{F}^{-1}(\frac{1}{\mathcal{F}(\mathbf{k})+\lambda}))\mathbf{y}$。</p>
</blockquote>
<p>The division is performed element-wise. Using Eq. 4, we finally obtain<br>该除法是逐元素执行的。使用式（4），我们最终得到</p>
<script type="math/tex; mode=display">\boldsymbol{\alpha}=\mathcal{F}^{-1}(\frac{\mathcal{F}(\mathbf{y})}{\mathcal{F}(\mathbf{k})+\lambda}).\tag{22}</script><blockquote>
<p>见补充材料性质2。</p>
</blockquote>
<h1 id="Appendix-A-2-Derivation-of-fast-detection-formula"><a href="#Appendix-A-2-Derivation-of-fast-detection-formula" class="headerlink" title="Appendix A.2: Derivation of fast detection formula"></a>Appendix A.2: Derivation of fast detection formula</h1><p>If we denote the test image by $\mathbf{z}$, detection amounts to classifying all the shifted test images $\mathbf{z}_{i}=P^{i}\mathbf{z}$. Each response is then given by<br>如果我们用$\mathbf{z}$表示测试图像，则检测意味着对所有移位的测试图像$\mathbf{z}_{i}=P^{i}\mathbf{z}$分类。然后每个响应由式（23）给出</p>
<script type="math/tex; mode=display">\hat{y}_{i}=\sum_{j}^{ }\alpha _{j}\kappa (P^{i}\mathbf{z},P^{j}\mathbf{x}),\tag{23}</script><p>since the training samples are $\mathbf{x}_{i}=P^{i}\mathbf{x}$ (Eq. 5). Rewriting it in matrix notation, the vector of all classifier responses is $\hat{\mathbf{y}}=C^{T}(\bar{\mathbf{k}})\boldsymbol{\alpha}$, where $\bar{\mathbf{k}}$ is the vector with elements $\bar{k}_{i}=\kappa (\mathbf{z},P^{i}\mathbf{x})$. We can now apply the convolution property (Eq. 4):<br>因为训练样本集是$\mathbf{x}_{i}=P^{i}\mathbf{x}$（式（5））。重写成矩阵形式，所有分类器响应的向量是$\hat{\mathbf{y}}=C^{T}(\bar{\mathbf{k}})\boldsymbol{\alpha}$，其中$\bar{\mathbf{k}}$是元素为$\bar{k}_{i}=\kappa (\mathbf{z},P^{i}\mathbf{x})$的向量。我们现在可以应用卷积性质（公式4）：</p>
<script type="math/tex; mode=display">\hat{\mathbf{y}}=\mathcal{F}^{-1}(\mathcal{F}(\bar{\mathbf{k}})\odot\mathcal{F}(\boldsymbol{\alpha})).\tag{24}</script><blockquote>
<p>见补充材料性质1和性质4。</p>
</blockquote>
<h1 id="Appendix-A-3-Generalization-of-circulant-forms"><a href="#Appendix-A-3-Generalization-of-circulant-forms" class="headerlink" title="Appendix A.3: Generalization of circulant forms"></a>Appendix A.3: Generalization of circulant forms</h1><p>For a matter of clarity, all of our derivations have assumed that the images are one-dimensional. The 2D case, despite its usefulness, is also more difficult to analyze. The reason is that the 2D generalization of a circulant matrix, related to the 2D Fourier Transform, is a Block-Circulant Circulant Matrix (BCCM, ie., a matrix that is circulant at the block level, composed of blocks themselves circulant). All of the properties we used for circulant matrices have BCCM equivalents.<br>为了明晰起见，我们所有的推导都假设图像是一维的。二维情况虽然有用，但也更难以分析。原因在于，与二维傅立叶变换相关的循环矩阵的二维泛化是块循环的循环矩阵（BCCM，即以块级别循环的矩阵，由块本身的循环组成）。我们用于循环矩阵的所有性质也适用于BCCM。<br>We will now generalize Theorem 1. A 1D image $\mathbf{x}$ can be shifted by $i$ with $P^i\mathbf{x}$. With a 2D image $X$, we can shift both its rows by $i$ and its columns by $i’$ with $P^iXP^{i’}$. Additionally, in an $n^2×n^2$ matrix $M$ composed of $n×n$ blocks, we will index the element $i’j’$ of the block $ij$ as $M_{(ii’),(jj’)}$.<br>我们现在将推广定理1。一个一维图像$\mathbf{x}$可以用$P^i\mathbf{x}$移位$i$次。对于2D图像$X$，我们可以使用$P^iXP^{i’}$同时将其行和列分别移位$i$和$i’$次。另外，在一个由$n×n$个块组成的$n^2×n^2$矩阵$M$中，我们将块$ij$的元素$i’j’$索引为$M_{(ii’),(jj’)}$。<br><strong>Theorem 2.</strong> The block matrix $K$ with elements $K_{(ii’),(jj’)}=\kappa(P^iXP^{i’},P^jXP^{j’})$ is a BCCM if $\kappa$ is a unitarily invariant kernel.<br><strong>定理2.</strong> 如果$\kappa$是一个酉不变核，具有元素$K_{(ii’),(jj’)}=\kappa(P^iXP^{i’},P^jXP^{j’})$的块矩阵$K$是BCCM。<br>$Proof.$ Because $\kappa$ is unitarily invariant, we have $K_{(ii’),(jj’)}=\kappa(X,P^{j-i}XP^{j’-i’})$. Since $K_{(ii’),(jj’)}$ depends only on $(j-i)$ mod $n$ and $(j’-i’)$ mod $n$, $K$ is BCCM.<br>证明。因为$\kappa$是酉不变的，我们有$K_{(ii’),(jj’)}=\kappa(X,P^{j-i}XP^{j’-i’})$。由于$K_{(ii’),(jj’)}$仅取决于$(j-i)$ mod $n$和$(j’-i’)$ mod $n$，因此$K$是BCCM。<br>$K$ can now be constructed as $C(K’)$, where the $n×n$ matrix $K’$ has elements $K_{ii’}=\kappa(X,P^{i}XP^{i’})$, and $C(\cdot)$ constructs a BCCM. The relevant solutions can then be re-derived with the 2D FT in place of the 1D FT.<br>$K$现在可以由$C(K’)$构造，其中$n×n$矩阵$K’$具有元素$K_{ii’}=\kappa(X,P^{i}XP^{i’})$，并且$C(\cdot)$构造一个BCCM。然后可以使用二维傅立叶变换代替一维傅立叶变换重新推导相关解。</p>
<blockquote>
<p>论文到此结束，下面是补充材料</p>
</blockquote>
<h1 id="Appendix-C-Additional-circulant-matrix-properties"><a href="#Appendix-C-Additional-circulant-matrix-properties" class="headerlink" title="Appendix C: Additional circulant matrix properties"></a>Appendix C: Additional circulant matrix properties</h1><p>This appendix will give more complete derivations of properties that, while easy enough to verify through direct computation, merit a more detailed analysis. These proofs were not included in the main paper to meet length requirements.<br>本附录将提供更完整的性质推导，虽然很容易通过直接计算进行验证，但其值得进行更详细的分析。这些证明未包含在论文中以满足论文的长度要求。<br>It also represents an attempt to better formalize the tools that were used in the main paper, and may be useful in other domains.<br>它还代表了一种尝试，使论文中使用的工具更形式化，并可能用于其它领域。<br>First we will formalize a definition given in Section 2.2. The fact that each row $i$ of $C(\mathbf{u})$ is given by $P^i\mathbf{u}$ can be expressed in the following way.<br>首先，我们将形式化第2.2节中给出的定义。$C(\mathbf{u})$的每一行$i$由$P^i\mathbf{u}$给出的事实可以用以下方式表示。<br><strong>Definition 1.</strong> The rows of an $n×n$ circulant matrix $C(\mathbf{u})$ are given by:<br><strong>定义1。</strong>$n×n$循环矩阵$C(\mathbf{u})$的行由式（25）给出</p>
<script type="math/tex; mode=display">C(\mathbf{u})=\begin{bmatrix}
(P^0\mathbf{u})^T\\ 
\vdots \\ 
(P^{n-1}\mathbf{u})^T
\end{bmatrix},\tag{25}</script><p>where $P$ is the $n×n$ permutation matrix that produces cyclic shifts of a vector,<br>其中$P$是$n×n$转置矩阵，使向量产生循环移位。</p>
<script type="math/tex; mode=display">P=\begin{bmatrix}
0 &  0&  0&  \cdots &1 \\ 
1&   0&  0&  \cdots &0\\ 
0&   1&  0&  \cdots &0\\ 
 \vdots & \vdots &  \ddots& \ddots  & \vdots\\ 
0&   0&  \cdots&  1 &0 
\end{bmatrix}.\tag{26}</script><p>$Property\ 1.$ <strong>Transposed circulant matrices and correlation</strong><br>Transposing a circulant matrix induces complex-conjugation in the Fourier domain; ie.,<br>转置一个循环矩阵将产生傅里叶域中的复共轭；即，</p>
<script type="math/tex; mode=display">C^T(\mathbf{u})=C(\mathcal{F}^{-1}(\mathcal{F}^{*}(\mathbf{u}))),\tag{27}</script><p>with $^{\ast}$ denoting the complex-conjugate. This suggests an alternative to Eq. 4, only with a transposed circulant matrix:<br>用$^{\ast}$表示复共轭。这表明了式（4）使用转置循环矩阵的另一种表示：</p>
<script type="math/tex; mode=display">C^T(\mathbf{u})\mathbf{v}=\mathcal{F}^{-1}(\mathcal{F}(\mathbf{u})\odot \mathcal{F}(\mathbf{v})).\tag{28}</script><p>Notice that the complex-conjugate was cancelled out. Eq. 28 can be understood as encoding correlation instead of convolution, which differ only by flipping the order of the elements of one of the input vectors.<br>注意到复共轭被消掉了。式（28）可以理解为编码相关而不是卷积，其不同之处在于仅翻转其中一个输入向量的元素的顺序。<br>Eq. 27 was used in Eq. 24 (Appendix A.2) to cancel out the complexconjugation from the $\mathcal{F}(\bar{\mathbf{k}})$ term.<br>式（27）被用于式（24）（附录A.2）中，以消掉$\mathcal{F}(\bar{\mathbf{k}})$项的复共轭。<br>$Property\ 2.$ <strong>Symmetricity of the reduced kernel matrix representation</strong><br>This property establishes that the vector $\mathbf{k}$, which compactly represents the kernel matrix through $K=C(\mathbf{k})$ (Eq. 6), is symmetric and thus has real Fourier transform:<br>此性质确定了通过$K=C(\mathbf{k})$（式（6））紧凑地表示了核矩阵的向量$\mathbf{k}$，如果是对称的则其具有实傅立叶变换：</p>
<script type="math/tex; mode=display">\mathcal{F}(\mathbf{k})=\mathcal{F}^{*}(\mathbf{k}).\tag{29}</script><p>This property was used in Eq. 22 to remove the complex-conjugation from the $1/(\mathcal{F}(\mathbf{k})+\lambda)$ term, which would arise from Eq. 4.<br>该性质被用于式（22）以从$1/(\mathcal{F}(\mathbf{k})+\lambda)$项中去除复共轭，式（22）来源于式（4）。<br>$Proof.$ The kernel matrix $K$ is symmetric $(K=K^T)$, due to positive definiteness of the kernel $\kappa$. From the compact representation of the kernel matrix $K=C(\mathbf{k})$ (Eq. 6), and Eq. 27 in Property 1, we get<br>证明。由于核$\kappa$的正定性，核矩阵$K$是对称的$(K=K^T)$。从核矩阵的紧凑表示$K=C(\mathbf{k})$（式（6））和性质1中的式（27），我们得到</p>
<script type="math/tex; mode=display">K^T=C^T(\mathbf{k})=C(\mathcal{F}^{-1}(\mathcal{F}^{*}(\mathbf{k}))).\tag{30}</script><p>Comparing it to $K=C(\mathbf{k})=C(\mathcal{F}^{-1}(\mathcal{F}(\mathbf{k})))$, we find that<br>将其与$K=C(\mathbf{k})=C(\mathcal{F}^{-1}(\mathcal{F}(\mathbf{k})))$比较，我们发现</p>
<script type="math/tex; mode=display">\mathcal{F}(\mathbf{k})=\mathcal{F}^{*}(\mathbf{k}).\tag{31}</script><p>As an aside, since $K=K^T$ we find that the vector $\mathbf{k}$ is also symmetric (its elements satisfy $k_{i}=k_{n-i}$). The fact that a symmetric signal has real Fourier transform is a well-known result from signal processing theory [21].<br>另外，由于$K=K^T$，我们发现向量$\mathbf{k}$也是对称的（它的元素满足$k_{i}=k_{n-i}$）。对称信号具有实傅立叶变换的事实是信号处理理论中众所周知的结果[21]。<br>$Property\ 3.$ <strong>Matrix form of dot-product kernels</strong><br>This property was used in Section 3.1, and establishes the equivalence between the definition of the elements of vector $\mathbf{k}^{dp}$<br>此性质在3.1节中使用，并确定了向量$\mathbf{k}^{dp}$中元素的定义</p>
<script type="math/tex; mode=display">k_{i}^{dp}=\kappa (\mathbf{x},P^{i}\mathbf{x'})=g(\mathbf{x}^{T}P^{i}\mathbf{x'}),\forall i=1,\ldots,n\tag{32}</script><p>and the same vector in matrix notation,<br>和同一向量的矩阵形式间的等价性，</p>
<script type="math/tex; mode=display">\mathbf{k}^{dp}=g(C(\mathbf{x'})\mathbf{x}).\tag{33}</script><p>$Proof.$ One way to prove this is to make some part of $k_{i}^{dp}$ conform to Definition 1, thus constructing a circulant matrix. Because $k_{i}^{dp}$ is a scalar,<br>证明。证明这一点的一种方法是使$k_{i}^{dp}$的某些部分符合定义1，从而构造循环矩阵。因为$k_{i}^{dp}$是一个标量，</p>
<script type="math/tex; mode=display">k_{i}^{dp}=g((P^i\mathbf{x}')^T\mathbf{x}).\tag{34}</script><p>Concatenating the elements into a vector, and since $g(\cdot)$ is an element-wise function,<br>将元素连接成一个向量，并且由于$g(\cdot)$是一个逐元素运算的函数，</p>
<script type="math/tex; mode=display">\mathbf{k}^{dp}=\begin{bmatrix}
g((P^0\mathbf{x}')^T\mathbf{x})\\ 
\vdots \\ 
g((P^{n-1}\mathbf{x}')^T\mathbf{x})
\end{bmatrix}=g\left ( \begin{bmatrix}
(P^0\mathbf{x}')^T\mathbf{x}\\ 
\vdots \\ 
(P^{n-1}\mathbf{x}')^T\mathbf{x}
\end{bmatrix} \right ).\tag{35}</script><p>Taking the $\mathbf{x}$ out of the multiplication, and using Definition 1, we get<br>从乘积中提出$\mathbf{x}$，并使用定义1，我们得到</p>
<script type="math/tex; mode=display">\mathbf{k}^{dp}=g\left ( \begin{bmatrix}
(P^0\mathbf{x}')^T\\ 
\vdots \\ 
(P^{n-1}\mathbf{x}')^T
\end{bmatrix} \mathbf{x}\right )=g(C(\mathbf{x'})\mathbf{x}).\tag{36}</script><p>$Property\ 4.$ <strong>Matrix form of kernel coefficients convolution</strong><br>This property was used in Section A.2 to prove Eq. 9, the fast detection formula. It consists of expressing Eq. 23 (reproduced here),<br>此性质在A.2节中被用于证明式（9），即快速检测公式。它包括式（23）（复述于此），</p>
<script type="math/tex; mode=display">\hat{y}_{i}=\sum_{j}^{ }\alpha _{j}\kappa (P^{i}\mathbf{z},P^{j}\mathbf{x}),\forall i=1,\ldots,n\tag{37}</script><p>in matrix form,<br>以矩阵形式，</p>
<script type="math/tex; mode=display">\hat{\mathbf{y}}=C^{T}(\bar{\mathbf{k}})\boldsymbol{\alpha},\tag{38}</script><p>where $\bar{\mathbf{k}}$ is the vector with elements $\bar{k}_{i}=\kappa (\mathbf{z},P^{i}\mathbf{x})$, and $\boldsymbol{\alpha}$ is the vector with elements $\alpha _{i}$.<br>其中$\bar{\mathbf{k}}$是元素为$\bar{k}_{i}=\kappa (\mathbf{z},P^{i}\mathbf{x})$的向量，且$\boldsymbol{\alpha}$是元素为$\alpha _{i}$的向量。<br>$Proof.$ We can build a kernel matrix $\bar{K}$ between shifted versions of $\mathbf{z}$ and shifted versions of $\mathbf{x}$, with elements<br>证明。我们可以在$\mathbf{z}$的移位和$\mathbf{x}$的移位之间建立一个核矩阵$\bar{K}$，带有元素</p>
<script type="math/tex; mode=display">\bar{k}_{ij}=\kappa (P^{i}\mathbf{z},P^{j}\mathbf{x}).\tag{39}</script><p>Note that, unlike the kernel matrix $K$ used for training, $\bar{K}$ is not necessarily symmetric, because $\mathbf{x}$ and $\mathbf{z}$ are different.<br>注意到与用于训练的核矩阵$K$不同，$\bar{K}$不一定是对称的，因为$\mathbf{x}$和$\mathbf{z}$是不同的。<br>Then, the elements in Eq. 37 can be concatenated into a vector $\hat{\mathbf{y}}$, and expressed as the multiplication<br>然后，式（37）中的元素可以连接成向量$\hat{\mathbf{y}}$，并表示为乘积</p>
<script type="math/tex; mode=display">\hat{\mathbf{y}}=\bar{K}^T\boldsymbol{\alpha},\tag{40}</script><p>which can be verified to be equivalent to Eq. 37 by direct computation.<br>可以通过直接计算验证它等价于式（37）。<br>With the same argument as Theorem 1, we can see that $\bar{K}$ is circulant. As such, we can express it in reduced form as $\bar{K}=C(\bar{\mathbf{k}})$, with the vector $\bar{\mathbf{k}}$ as defined earlier. We then obtain<br>与定理1的论证相同，我们可以看出$\bar{K}$是循环的。因此，我们可以用如$\bar{K}=C(\bar{\mathbf{k}})$的简化形式表示它，其中向量$\bar{\mathbf{k}}$如前所述。然后我们得到</p>
<script type="math/tex; mode=display">\hat{\mathbf{y}}=C^{T}(\bar{\mathbf{k}})\boldsymbol{\alpha}.\tag{41}</script><p><sup><a href="#fn_1" id="reffn_1">1</a></sup>:We refer the reader to 2 reviews: [8] is more in-depth, while [9, Sec. 3] is more recent.<br>我们向读者推荐两个文献综述：[8]更深入，而[9, Sec. 3]是近期的。<br><sup><a href="#fn_2" id="reffn_2">2</a></sup>:The bias term b is not important in practice, when finding the maximum response.<br>在找最大响应时，偏差项b在实际中并不重要。</p>

      
    </div>
    
    
    

    

    

    
      <div>
        <ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者：</strong>
    Sarieli
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://yoursite.com/2018/11/01/Exploiting the Circulant Structure of Tracking-by-detection with Kernels 渣翻/" title="Exploiting the Circulant Structure of Tracking-by-detection with Kernels 渣翻">http://yoursite.com/2018/11/01/Exploiting the Circulant Structure of Tracking-by-detection with Kernels 渣翻/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>
    本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> 许可协议。转载请注明出处！
  </li>
</ul>

      </div>
    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/相关滤波/" rel="tag"># 相关滤波</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/11/18/High-Speed Tracking with Kernelized Correlation Filters 渣翻/" rel="prev" title="High-Speed Tracking with Kernelized Correlation Filters 渣翻">
                High-Speed Tracking with Kernelized Correlation Filters 渣翻 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/avatar.png" alt="Sarieli">
            
              <p class="site-author-name" itemprop="name">Sarieli</p>
              <p class="site-description motion-element" itemprop="description">大道甚夷，而人好径</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">1</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">1</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Introduction"><span class="nav-number">1.</span> <span class="nav-text">Introduction</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Previous-work"><span class="nav-number">1.1.</span> <span class="nav-text">Previous work</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Contributions"><span class="nav-number">1.2.</span> <span class="nav-text">Contributions</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Learning-with-dense-sampling"><span class="nav-number">2.</span> <span class="nav-text">Learning with dense sampling</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Regularized-risk-minimization"><span class="nav-number">2.1.</span> <span class="nav-text">Regularized risk minimization</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Circulant-matrices"><span class="nav-number">2.2.</span> <span class="nav-text">Circulant matrices</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#The-kernel-matrix-with-dense-sampling"><span class="nav-number">2.3.</span> <span class="nav-text">The kernel matrix with dense sampling</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Efficient-Kernel-Regularized-Least-Squares-solution"><span class="nav-number">2.4.</span> <span class="nav-text">Efficient Kernel Regularized Least Squares solution</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Fast-detection"><span class="nav-number">2.5.</span> <span class="nav-text">Fast detection</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Fast-computation-of-non-linear-kernels"><span class="nav-number">3.</span> <span class="nav-text">Fast computation of non-linear kernels</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Dot-product-kernels"><span class="nav-number">3.1.</span> <span class="nav-text">Dot-product kernels</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Radial-Basis-Function-kernels"><span class="nav-number">3.2.</span> <span class="nav-text">Radial Basis Function kernels</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#The-linear-case"><span class="nav-number">3.3.</span> <span class="nav-text">The linear case</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Experiments"><span class="nav-number">4.</span> <span class="nav-text">Experiments</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Pre-processing"><span class="nav-number">4.1.</span> <span class="nav-text">Pre-processing</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Training-outputs"><span class="nav-number">4.2.</span> <span class="nav-text">Training outputs</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Overview"><span class="nav-number">4.3.</span> <span class="nav-text">Overview</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Evaluation"><span class="nav-number">4.4.</span> <span class="nav-text">Evaluation</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Conclusion"><span class="nav-number">5.</span> <span class="nav-text">Conclusion</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Appendix-A-1-Dense-Sampling-KRLS-derivation"><span class="nav-number">6.</span> <span class="nav-text">Appendix A.1: Dense Sampling KRLS derivation</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Appendix-A-2-Derivation-of-fast-detection-formula"><span class="nav-number">7.</span> <span class="nav-text">Appendix A.2: Derivation of fast detection formula</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Appendix-A-3-Generalization-of-circulant-forms"><span class="nav-number">8.</span> <span class="nav-text">Appendix A.3: Generalization of circulant forms</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Appendix-C-Additional-circulant-matrix-properties"><span class="nav-number">9.</span> <span class="nav-text">Appendix C: Additional circulant matrix properties</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<div class="copyright">&copy; <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Sarieli</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count">35.9k</span>
  
</div>

<div class="powered-by">
<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
  访问人数 <span id="busuanzi_value_site_uv"></span>
</span>
</div>

<span id="busuanzi_container_site_pv">
  总阅读量 <span id="busuanzi_value_site_pv"></span>
</span>

<!--


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>


-->



        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  




  
  
  
  <link rel="stylesheet" href="/lib/algolia-instant-search/instantsearch.min.css">

  
  
  <script src="/lib/algolia-instant-search/instantsearch.min.js"></script>
  

  <script src="/js/src/algolia-search.js?v=5.1.4"></script>



  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("9KDsTY6EkCBGjRausf1kf6LC-gzGzoHsz", "1VTtq7tsYmHGToQSADoWzFy3");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.staticfile.org/MathJax/MathJax-2.6-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
